# Utilisation de Spark en Python via l'API PySpark

Internet, l’apparition de la 3G, 4G et actuellement de la 5G, les grandes 
installations scientifiques génèrent une immensité de données traitables. En 2020 
une analyse a révélé que 40 zéctaoctets sont générés par an, 204 millions d’e-mails 
sont envoyés chaque minute. L’ensemble de ces données ainsi que les enjeux qui y 
sont associés représente la notion de Big Data.

Concevoir une infrastructure Big data aujourd’hui consiste à distribuer de 
manière intelligente et efficace le stockage et les traitements de ces données. Il s’agit 
principalement de repenser le stockage comme le fait d’utiliser systèmes de fichiers 
tels que HDFS de Hadoop et les algorithmes de traitement des données comme 
l’utilisation de MapReduce ou de Spark.

Dans cette partie, nous allons utiliser Spark en Python via l’API PySpark. 
PySpark est une interface pour Apache Spark en Python. Elle nous permet 
non seulement d’écrire des applications Spark à l’aide d’API Python, mais fournit 
également le shell PySpark pour analyser interactivement les données dans un 
environnement distribué. 

PySpark supporte la plupart des fonctionnalités de Spark telles que Spark 
SQL, DataFrame, Streaming, MLlib (Machine Learning) et Spark Core.
